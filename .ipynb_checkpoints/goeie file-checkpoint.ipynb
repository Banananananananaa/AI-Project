{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import wordnet as wn\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv(\"berichten-09-06-2017_10-49.csv\", sep=';')\n",
    "nlp = spacy.load('nl')\n",
    "# Functie die van een lijst gebruikers de unieke namen teruggeeft. in progress\n",
    "def get_Users(df):\n",
    "    users = []\n",
    "    for g in df.Gebruiker:\n",
    "        u = g#.lower()\n",
    "        if u not in users:\n",
    "            users.append(u)    \n",
    "    return users\n",
    "\n",
    "# Functie die een b[ericht normarliseerd door de @, # en links verwijderd, waarna het \n",
    "# de pos tags vindt en die returned\n",
    "def pos_tags(bericht):\n",
    "    b = re.sub('@'+'\\w+','',bericht)\n",
    "    b = re.sub('#'+'\\w+','',b)\n",
    "    b = re.sub('http'+'\\S+', '', b)\n",
    "    b = re.findall('\\w+', b)\n",
    "    b = ' '.join(b)\n",
    "    b = unicode(b, \"utf-8\")\n",
    "    doc = nlp(b)\n",
    "    tags = []\n",
    "    for word in doc:\n",
    "        if word.tag_ == u'NOUN' or word.tag_ == u'VERB' or word.tag_ == u'ADJ' or word.tag_ == u'ADV':\n",
    "            tags.append((word, word.tag_))\n",
    "    return tags\n",
    "#Functie die door middel van regular expressions kandidaat keywords samenstelt.\n",
    "def regex_Tags(bericht):\n",
    "    b = re.sub('@'+'\\w+','',bericht)\n",
    "    b = re.sub('#'+'\\w+','',b)\n",
    "    b = re.sub('http'+'\\S+', '', b)\n",
    "    b = re.findall('\\w+', b)\n",
    "    b = ' '.join(b)\n",
    "    b = unicode(b, \"utf-8\")\n",
    "    doc = nlp(b)\n",
    "    tags = []\n",
    "    l = len(doc)\n",
    "    for i in range(0, l-1):\n",
    "        if (i + 1):\n",
    "            if (doc[i].tag_ == u'ADJ' or doc[i].tag_ == u'NOUN') and doc[i+1].tag_ == u'NOUN':\n",
    "                tags.append((doc[i], doc[i+1]))\n",
    "            elif doc[i].tag_ == u'VERB' and (doc[i+1].tag_ == u'ADJ' or doc[i+1].tag_ == u'NOUN'):\n",
    "                tags.append((doc[i], doc[i+1]))\n",
    "            elif doc[i].tag_ == u'VERB' and (doc[i+1].tag_ == u'ADJ' or doc[i+1].tag_ == u'NOUN') and doc[i+2].tag_ == u'NOUN':\n",
    "                tags.append((doc[i], doc[i+1], docc[i+2]))\n",
    "\n",
    "    return tags\n",
    "\n",
    "\n",
    "# Functie die van een lijst gebruikers de berichten verzameld.\n",
    "def get_Messages(df):\n",
    "    messages = {}\n",
    "    users = get_Users(df)\n",
    "    for u in users:\n",
    "        messages.update({u : df.Bericht.loc[df['Gebruiker'] == u]})\n",
    "    return messages\n",
    "\n",
    "def get_Tags(df):\n",
    "    user = []\n",
    "    tag = []\n",
    "    regex = []\n",
    "    for i in range(0, len(df.Bericht)):\n",
    "        user.append(df.Gebruiker[i].lower())\n",
    "        tag.append(pos_tags(df.Bericht[i]))\n",
    "        regex.append(regex_Tags(df.Bericht[i]))\n",
    "    tags = pd.DataFrame({'Gebruiker':user, 'Tags':tag, 'Regex':regex})\n",
    "    return tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-40a26989654b>, line 91)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-40a26989654b>\"\u001b[0;36m, line \u001b[0;32m91\u001b[0m\n\u001b[0;31m    class KeywordCandidateGenerator(CandidateGenerator):\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import abc\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import translator\n",
    "\t\n",
    "\n",
    "\n",
    "class preprocessor():\n",
    "    @classmethod\n",
    "    def preprocess(cls, text):\n",
    "        \"\"\"removes noise from the tweets\"\"\"\n",
    "    \n",
    "class Translation():\n",
    "    @classmethod\n",
    "    def translate(cls, language1, language2, text):\n",
    "        \"\"\"Translates from a language to the desired language if deemed necessary\"\"\"\n",
    "\n",
    "class POStagger():\n",
    "    @classmethod\n",
    "    def tag(cls, text):\n",
    "        \"\"\"Assigns tags to each word in the tweet\"\"\"\n",
    "\n",
    "class CandidateGenerator():\n",
    "    @classmethod\n",
    "    def generate_candidates(cls, tokenized_text):\n",
    "        \"\"\"generates candidates from the tokens as specified\"\"\"\n",
    "\n",
    "\n",
    "class CandidateRanker():\n",
    "    @classmethod\n",
    "    def rank(candidates):\n",
    "        \"\"\"rankes the candidates\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class atremoval(preprocessor):\n",
    "    @classmethod\n",
    "    def preprocess(cls, text):\n",
    "        text = re.sub('@'+'\\w+', '', text)\n",
    "        return text\n",
    "\n",
    "class hashtagremoval(preprocessor):\n",
    "    @classmethod\n",
    "    def preprocess(cls, text):\n",
    "        text = re.sub('#'+'\\w+','', text)\n",
    "        return text\n",
    "\n",
    "class linkremoval(preprocessor):\n",
    "    @classmethod\n",
    "    def preprocess(cls, text):\n",
    "        text = re.sub('http'+'\\S+', '', text)\n",
    "        return text\n",
    "\n",
    "class AutomaticSumerization(preprocessor):\n",
    "    @classmethod\n",
    "    def preprocess(cls, link):\n",
    "        LANGUAGE = \"english\"\n",
    "        SENTENCES_COUNT = 10\n",
    "        url = link\n",
    "        parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "        stemmer = Stemmer(LANGUAGE)\n",
    "        summarizer = Summarizer(stemmer)\n",
    "        summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "        text = summarizer(parser.document, SENTENCES_COUNT) \n",
    "        return text\n",
    "class Translator(translation):\n",
    "    @classmethod\n",
    "    def translate(cls, language1, language2, text):\n",
    "        translator = Translator(from_lang=language1, to_lang=language2)\n",
    "        return translator.translate(text)\t\t\n",
    "\n",
    "class SpacyPOStagger(POStagger):\n",
    "    @classmethod\n",
    "    def tag(cls, text):\n",
    "        nlp = spacy.load('nl')\n",
    "        text = nlp(text)\n",
    "\n",
    "class NltkPOStagger(POStagger):\n",
    "    @classmethod\n",
    "    def tag(cls, text):\n",
    "        text = nltk.pos_tag(text)\n",
    "        return text\n",
    "\n",
    "class RegexCandidateGenerator(CandidateGenerator):\n",
    "    @classmethod\n",
    "    def generate_candidates(cls, tokenized_text):\n",
    "        #generate regex keywords\n",
    "\n",
    "class KeywordCandidateGenerator(CandidateGenerator):\n",
    "    @classmethod\n",
    "    def generate_candidates(cls, tokenized_text):\n",
    "        #generate keywords with one pos tag\n",
    "\n",
    "class TfidfRanker(CandidateRanker):\n",
    "    @classmethod\n",
    "    def rank(cls, candidates):\n",
    "        #tfidf\n",
    "\n",
    "def main(tweets, translate):\n",
    "    preprocessors = []\n",
    "    preprocessors.append(atremoval)\n",
    "    preprocessors.append(hashtagremoval)\n",
    "    preprocessors.append(linkremoval)\n",
    "    candidate_generator = KeywordCandidateGenerator\n",
    "    tokenizer = NltkPOStagger\n",
    "    ranker = TfidfRanker\n",
    "    all_candidates = set()\n",
    "    translating = Translator\n",
    "\n",
    "    #if translate == TRUE:\n",
    "     #   translating.translate(cls, language1, language2 tweets)\n",
    "    #for tweet in tweets:\n",
    "        for preprocessor in preprocessors:\n",
    "            tweet = preprocessor.preprocess(tweet)\n",
    "        tokenizer.tag(tweet)\n",
    "        #candidates = candidate_generator.generate_candidates(tokenizer.tag(tweet))\n",
    "        #all_candidates += candidates\n",
    "        \n",
    "    #ranked_words = ranker.rank(all_candidates)\n",
    "    #interest = select(ranked_words)\n",
    "    #print interest\n",
    "main(\"hallo @schiphol, #veilig http://eeeeey.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.Counter"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def word_Count(bericht):\n",
    "    b = re.sub('@'+'\\w+','',bericht)\n",
    "    b = re.sub('#'+'\\w+','',b)\n",
    "    b = re.sub('http'+'\\S+', '', b)\n",
    "    b = re.findall('\\w+', b)\n",
    "    b = ' '.join(b)\n",
    "    b = unicode(b, \"utf-8\")#tot hier en niet verder\n",
    "    doc = nlp(b)\n",
    "    words = []\n",
    "    for i in range(0, len(doc)):\n",
    "        word = doc[i]\n",
    "        if  word.tag_ == u'NOUN' or word.tag_ == u'VERB' or word.tag_ == u'ADJ' or word.tag_ == u'ADV':\n",
    "            words.append(str(doc[i]))\n",
    "    counts = Counter(words)\n",
    "    return counts\n",
    "    \n",
    "x1 = word_Count(df.Bericht[999])\n",
    "x2 = word_Count(df.Bericht[0])\n",
    "x3 = word_Count(df.Bericht[1])\n",
    "\n",
    "\n",
    "type(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '00',\n",
       " '000',\n",
       " '00u',\n",
       " '01',\n",
       " '010',\n",
       " '02',\n",
       " '03',\n",
       " '030',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '0624820470',\n",
       " '0657585703',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '0906',\n",
       " '1',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '100mtr',\n",
       " '100ste',\n",
       " '101',\n",
       " '104',\n",
       " '10en',\n",
       " '11',\n",
       " '1100',\n",
       " '112',\n",
       " '12',\n",
       " '123',\n",
       " '129',\n",
       " '13',\n",
       " '137',\n",
       " '13h',\n",
       " '14',\n",
       " '140',\n",
       " '140307',\n",
       " '1428',\n",
       " '14games',\n",
       " '15',\n",
       " '150',\n",
       " '158',\n",
       " '15x',\n",
       " '16',\n",
       " '17',\n",
       " '1700',\n",
       " '175',\n",
       " '18',\n",
       " '1850',\n",
       " '187',\n",
       " '19',\n",
       " '190',\n",
       " '190516',\n",
       " '1945',\n",
       " '1950',\n",
       " '1969',\n",
       " '1973',\n",
       " '1990',\n",
       " '1e',\n",
       " '1ste',\n",
       " '1x',\n",
       " '2',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2010',\n",
       " '2012',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2022',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '24e',\n",
       " '24u',\n",
       " '25',\n",
       " '256',\n",
       " '25th',\n",
       " '26',\n",
       " '269',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '29ste',\n",
       " '2D',\n",
       " '2de',\n",
       " '2e',\n",
       " '2l',\n",
       " '2x',\n",
       " '3',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30k',\n",
       " '31',\n",
       " '31x',\n",
       " '32',\n",
       " '320',\n",
       " '321',\n",
       " '327',\n",
       " '328',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '360',\n",
       " '365',\n",
       " '37',\n",
       " '380',\n",
       " '382',\n",
       " '39',\n",
       " '3FM',\n",
       " '3e',\n",
       " '3x',\n",
       " '4',\n",
       " '40',\n",
       " '400',\n",
       " '425',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '450',\n",
       " '452',\n",
       " '47',\n",
       " '48',\n",
       " '480',\n",
       " '49',\n",
       " '4sq',\n",
       " '4x',\n",
       " '5',\n",
       " '50',\n",
       " '51',\n",
       " '5125',\n",
       " '52',\n",
       " '530',\n",
       " '54',\n",
       " '55',\n",
       " '555',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '599',\n",
       " '5de',\n",
       " '5e',\n",
       " '5l',\n",
       " '5x',\n",
       " '5xx',\n",
       " '6',\n",
       " '60',\n",
       " '600',\n",
       " '60e',\n",
       " '61',\n",
       " '64',\n",
       " '640',\n",
       " '649',\n",
       " '65',\n",
       " '650',\n",
       " '69',\n",
       " '6u',\n",
       " '6x',\n",
       " '7',\n",
       " '70',\n",
       " '720',\n",
       " '721',\n",
       " '74',\n",
       " '75',\n",
       " '78',\n",
       " '7k',\n",
       " '7th',\n",
       " '8',\n",
       " '80',\n",
       " '800',\n",
       " '85',\n",
       " '873',\n",
       " '893',\n",
       " '8c',\n",
       " '9',\n",
       " '90',\n",
       " '9000',\n",
       " '90jarige',\n",
       " '933',\n",
       " '94',\n",
       " '95',\n",
       " '973',\n",
       " '99',\n",
       " 'ALTIJD',\n",
       " 'Aahw',\n",
       " 'Aanmelden',\n",
       " 'Aanrader',\n",
       " 'Aanstaande',\n",
       " 'Aantrekkelijk',\n",
       " 'Absolute',\n",
       " 'Absoluut',\n",
       " 'Ahaa',\n",
       " 'Ahead',\n",
       " 'Al',\n",
       " 'Alarm',\n",
       " 'Aldus',\n",
       " 'Algemeen',\n",
       " 'Ali',\n",
       " 'Alleen',\n",
       " 'Alsnog',\n",
       " 'Altijd',\n",
       " 'Alvast',\n",
       " 'Amerikaanse',\n",
       " 'Amsterdamse',\n",
       " 'Anders',\n",
       " 'Arabisch',\n",
       " 'Arme',\n",
       " 'Autocorrect',\n",
       " 'Avondvierdaagse',\n",
       " 'Awakens',\n",
       " 'Award',\n",
       " 'Awards',\n",
       " 'Bada',\n",
       " 'Batterij',\n",
       " 'Bedankt',\n",
       " 'Beemsterse',\n",
       " 'Begrijpelijk',\n",
       " 'Bekende',\n",
       " 'Bekijk',\n",
       " 'Belangrijker',\n",
       " 'Belgische',\n",
       " 'Beme',\n",
       " 'Berlijnse',\n",
       " 'Best',\n",
       " 'Beste',\n",
       " 'Beter',\n",
       " 'Betere',\n",
       " 'Beverproblematiek',\n",
       " 'Bezig',\n",
       " 'Biiiijjjjjna',\n",
       " 'Bijna',\n",
       " 'Bijzonder',\n",
       " 'Bijzondere',\n",
       " 'Bikkel',\n",
       " 'Binnenkort',\n",
       " 'Blauwe',\n",
       " 'Blij',\n",
       " 'Blije',\n",
       " 'Blijkbaar',\n",
       " 'Bluetooth',\n",
       " 'Brabantse',\n",
       " 'Break',\n",
       " 'Briljante',\n",
       " 'Broederliefde',\n",
       " 'Bruisende',\n",
       " 'Buiten',\n",
       " 'Burger',\n",
       " 'Burgerlijke',\n",
       " 'Bussemaker',\n",
       " 'Buzzcapture',\n",
       " 'Cardiologische',\n",
       " 'Centraal',\n",
       " 'Checklist',\n",
       " 'Chinese',\n",
       " 'Commentaar',\n",
       " 'Community',\n",
       " 'Complete',\n",
       " 'Congrats',\n",
       " 'Content',\n",
       " 'DAAROP',\n",
       " 'DRIE',\n",
       " 'Daar',\n",
       " 'Daarmee',\n",
       " 'Daarna',\n",
       " 'Daarom',\n",
       " 'Daarvoor',\n",
       " 'Dan',\n",
       " 'Dankbaar',\n",
       " 'Dankjewel',\n",
       " 'Daredevils',\n",
       " 'Das',\n",
       " 'Datamanager',\n",
       " 'Deense',\n",
       " 'Delen',\n",
       " 'Deutsche',\n",
       " 'Developer',\n",
       " 'Digitale',\n",
       " 'Dikke',\n",
       " 'Dikketjes',\n",
       " 'Dinsdagmodus',\n",
       " 'Direct',\n",
       " 'Doei',\n",
       " 'Dreams',\n",
       " 'Drie',\n",
       " 'Drop',\n",
       " 'Druk',\n",
       " 'Dubbel',\n",
       " 'Duidelijk',\n",
       " 'Duits',\n",
       " 'Duitse',\n",
       " 'Dus',\n",
       " 'Duur',\n",
       " 'EINDELIJK',\n",
       " 'EVEN',\n",
       " 'Echt',\n",
       " 'Echte',\n",
       " 'Echter',\n",
       " 'Eens',\n",
       " 'Eerst',\n",
       " 'Eerste',\n",
       " 'Eeuwige',\n",
       " 'Eigenlijk',\n",
       " 'Eindelijk',\n",
       " 'Elektromonteur',\n",
       " 'En',\n",
       " 'Engels',\n",
       " 'Engelse',\n",
       " 'Enjoy',\n",
       " 'Enne',\n",
       " 'Enorm',\n",
       " 'Er',\n",
       " 'Erbij',\n",
       " 'Erg',\n",
       " 'Ergens',\n",
       " 'Esquire',\n",
       " 'Europees',\n",
       " 'Europese',\n",
       " 'Even',\n",
       " 'Event',\n",
       " 'Exact',\n",
       " 'Exclusief',\n",
       " 'Extra',\n",
       " 'F',\n",
       " 'F8',\n",
       " 'FB',\n",
       " 'Facker',\n",
       " 'Fantastisch',\n",
       " 'Fantastische',\n",
       " 'Fascisten',\n",
       " 'Fashiolista',\n",
       " 'Featured',\n",
       " 'Federale',\n",
       " 'Feel',\n",
       " 'Feiten',\n",
       " 'Fijn',\n",
       " 'Fijne',\n",
       " 'Footlocker',\n",
       " 'Fotoshoot',\n",
       " 'Frans',\n",
       " 'Franse',\n",
       " 'Fries',\n",
       " 'Friese',\n",
       " 'Fuck',\n",
       " 'Futuristische',\n",
       " 'GOED',\n",
       " 'GROOT',\n",
       " 'Gaaf',\n",
       " 'Gefeliciteerd',\n",
       " 'Gelukkig',\n",
       " 'Generale',\n",
       " 'Geniaal',\n",
       " 'Genoeg',\n",
       " 'Geweldig',\n",
       " 'Geweldige',\n",
       " 'Gewoon',\n",
       " 'Gezellig',\n",
       " 'Gigantische',\n",
       " 'Glad',\n",
       " 'Goed',\n",
       " 'Goede',\n",
       " 'Goedemorgen',\n",
       " 'Goeie',\n",
       " 'Gouden',\n",
       " 'Graag',\n",
       " 'Grafisch',\n",
       " 'Grande',\n",
       " 'Grappige',\n",
       " 'Gratis',\n",
       " 'Grolsch',\n",
       " 'Groot',\n",
       " 'Grootste',\n",
       " 'Grote',\n",
       " 'HEEL',\n",
       " 'HIER',\n",
       " 'Haarlemse',\n",
       " 'Haha',\n",
       " 'Hahah',\n",
       " 'Hair',\n",
       " 'Halve',\n",
       " 'Handig',\n",
       " 'Handige',\n",
       " 'Heeeel',\n",
       " 'Heel',\n",
       " 'Heerlijk',\n",
       " 'Heerlijke',\n",
       " 'Heftig',\n",
       " 'Heftige',\n",
       " 'Heilooer',\n",
       " 'Helaas',\n",
       " 'Hele',\n",
       " 'Helemaal',\n",
       " 'Herkenbaar',\n",
       " 'Hier',\n",
       " 'Hierbij',\n",
       " 'Hiermee',\n",
       " 'Hoe',\n",
       " 'Hoge',\n",
       " 'Holland',\n",
       " 'Hollandse',\n",
       " 'Honderdduizenden',\n",
       " 'Hongaarse',\n",
       " 'Hoogwaardige',\n",
       " 'Hopelijk',\n",
       " 'Hulpvaardige',\n",
       " 'Ieder',\n",
       " 'Iemand',\n",
       " 'Ilse',\n",
       " 'Inclusief',\n",
       " 'Inderdaad',\n",
       " 'Indische',\n",
       " 'Ineens',\n",
       " 'Infantino',\n",
       " 'Inmiddels',\n",
       " 'Innerlijke',\n",
       " 'Inspirerend',\n",
       " 'Interessant',\n",
       " 'Interessante',\n",
       " 'Internationale',\n",
       " 'Interne',\n",
       " 'Intrinsiek',\n",
       " 'Investeerder',\n",
       " 'Inzet',\n",
       " 'It',\n",
       " 'Itali',\n",
       " 'Ja',\n",
       " 'Jaarlijkse',\n",
       " 'Jammer',\n",
       " 'Jazeker',\n",
       " 'Jemig',\n",
       " 'Jenneke',\n",
       " 'Jeroen',\n",
       " 'Jihaaaa',\n",
       " 'Juist',\n",
       " 'Kijk',\n",
       " 'Klaar',\n",
       " 'Klaver',\n",
       " 'Klein',\n",
       " 'Korte',\n",
       " 'Koud',\n",
       " 'Koude',\n",
       " 'Krachtige',\n",
       " 'L',\n",
       " 'LEUK',\n",
       " 'LIVE',\n",
       " 'Laat',\n",
       " 'Laatste',\n",
       " 'Lang',\n",
       " 'Lange',\n",
       " 'Langzaam',\n",
       " 'Later',\n",
       " 'Leads',\n",
       " 'Legendarische',\n",
       " 'Lekker',\n",
       " 'Lesbische',\n",
       " 'Letterlijk',\n",
       " 'Leuk',\n",
       " 'Leuke',\n",
       " 'Lief',\n",
       " 'Lieve',\n",
       " 'Liever',\n",
       " 'Light',\n",
       " 'LinkedIn',\n",
       " 'Live',\n",
       " 'Livin',\n",
       " 'Logisch',\n",
       " 'Loosdrechtse',\n",
       " 'Maar',\n",
       " 'Machtig',\n",
       " 'Management',\n",
       " 'Master',\n",
       " 'Mateloos',\n",
       " 'Mede',\n",
       " 'Medewerker',\n",
       " 'Meedoen',\n",
       " 'Meer',\n",
       " 'Meest',\n",
       " 'Meestal',\n",
       " 'Meeste',\n",
       " 'Meldingen',\n",
       " 'Mentale',\n",
       " 'Merkdeskundige',\n",
       " 'Messenger',\n",
       " 'Meteen',\n",
       " 'Midden',\n",
       " 'Minimaal',\n",
       " 'Misdaad',\n",
       " 'Misschien',\n",
       " 'Mobiele',\n",
       " 'Modern',\n",
       " 'Moeilijk',\n",
       " 'Mooi',\n",
       " 'Mooie',\n",
       " 'Morgen',\n",
       " 'NIET',\n",
       " 'NU',\n",
       " 'Naamgenoten',\n",
       " 'Nationale',\n",
       " 'Natuurlijk',\n",
       " 'Nederlands',\n",
       " 'Nederlandse',\n",
       " 'Nederlandstalige',\n",
       " 'Neehoor',\n",
       " 'Nergens',\n",
       " 'Net',\n",
       " 'Newsroom',\n",
       " 'Niet',\n",
       " 'Nietzsche',\n",
       " 'Nieuw',\n",
       " 'Nieuwe',\n",
       " 'Nieuwsgierig',\n",
       " 'Nijmeegse',\n",
       " 'Nike',\n",
       " 'Nog',\n",
       " 'Nogmaals',\n",
       " 'Nooit',\n",
       " 'Noooooo',\n",
       " 'Normaal',\n",
       " 'Normale',\n",
       " 'Nostalgisch',\n",
       " 'Nostalgische',\n",
       " 'Nou',\n",
       " 'Nu',\n",
       " 'O',\n",
       " 'OBI4wan',\n",
       " 'ONGELOOFLIJK',\n",
       " 'OOK',\n",
       " 'OVERAL',\n",
       " 'Oeps',\n",
       " 'Officieel',\n",
       " 'Oisterwijk',\n",
       " 'Oja',\n",
       " 'Olympische',\n",
       " 'Onbekende',\n",
       " 'Ondertussen',\n",
       " 'Onderweg',\n",
       " 'Onderzoeksverpleegkundige',\n",
       " 'Onee',\n",
       " 'Ongelooflijk',\n",
       " 'Ongelukkig',\n",
       " 'Ongeneeslijk',\n",
       " 'Ongeveer',\n",
       " 'Ongewoon',\n",
       " 'Onlangs',\n",
       " 'Online',\n",
       " 'Ons',\n",
       " 'Ontwikkelaar',\n",
       " 'Ontzettend',\n",
       " 'Ooit',\n",
       " 'Ook',\n",
       " 'Open',\n",
       " 'Opkomst',\n",
       " 'Optical',\n",
       " 'Optimale',\n",
       " 'Oude',\n",
       " 'Outcome',\n",
       " 'Over',\n",
       " 'Overigens',\n",
       " 'Overmars',\n",
       " 'P',\n",
       " 'PR',\n",
       " 'Pas',\n",
       " 'Passieve',\n",
       " 'People',\n",
       " 'Persoonlijk',\n",
       " 'Pijnlijk',\n",
       " 'Pittig',\n",
       " 'Plus',\n",
       " 'Positief',\n",
       " 'Prachtbaan',\n",
       " 'Prachtig',\n",
       " 'Prachtige',\n",
       " 'Praktisch',\n",
       " 'Precies',\n",
       " 'Prima',\n",
       " 'Probeer',\n",
       " 'Productief',\n",
       " 'Pure',\n",
       " 'QUOTE',\n",
       " 'Quote',\n",
       " 'Raar',\n",
       " 'Rare',\n",
       " 'Realtime',\n",
       " 'Redelijk',\n",
       " 'Reden',\n",
       " 'Rentenieuwsgierig',\n",
       " 'Responsieve',\n",
       " 'Roemer',\n",
       " 'Ronde',\n",
       " 'Ruim',\n",
       " 'Russische',\n",
       " 'Samen',\n",
       " 'Scale',\n",
       " 'Schade',\n",
       " 'Scherp',\n",
       " 'Schone',\n",
       " 'Sem',\n",
       " 'Serieus',\n",
       " 'Servische',\n",
       " 'Slecht',\n",
       " 'Sociaal',\n",
       " 'Social',\n",
       " 'Sociale',\n",
       " 'Solliciteer',\n",
       " 'Soms',\n",
       " 'Spannend',\n",
       " 'Spannende',\n",
       " 'Speciaal',\n",
       " 'Stagiair',\n",
       " 'Sterk',\n",
       " 'Sterke',\n",
       " 'Stevig',\n",
       " 'Stiekem',\n",
       " 'Stil',\n",
       " 'Stoere',\n",
       " 'Stop',\n",
       " 'Straks',\n",
       " 'Succesvol',\n",
       " 'Superschattig',\n",
       " 'Syrische',\n",
       " 'TL',\n",
       " 'Te',\n",
       " 'Tekort',\n",
       " 'Tenminste',\n",
       " 'Terecht',\n",
       " 'Terre',\n",
       " 'Terug',\n",
       " 'Test',\n",
       " 'Thanks',\n",
       " 'Things',\n",
       " 'Thuis',\n",
       " 'Tien',\n",
       " 'Time',\n",
       " 'Tip',\n",
       " 'Toch',\n",
       " 'Toen',\n",
       " 'Toffe',\n",
       " 'Toi',\n",
       " 'Tot',\n",
       " 'Trots',\n",
       " 'Trotse',\n",
       " 'Trouwens',\n",
       " 'Trump',\n",
       " 'Turkse',\n",
       " 'Tuurlijk',\n",
       " 'Twee',\n",
       " 'Tweede',\n",
       " 'Tweetinspiratieloos',\n",
       " 'Twintig',\n",
       " 'Twintigste',\n",
       " 'Twitter',\n",
       " 'U',\n",
       " 'Uiteindelijk',\n",
       " 'V',\n",
       " 'VIDEO',\n",
       " 'Vaak',\n",
       " 'Vaarwel',\n",
       " 'Vanavond',\n",
       " 'Vandaag',\n",
       " 'Vandaar',\n",
       " 'Vannacht',\n",
       " 'Vast',\n",
       " 'Veilige',\n",
       " 'Velen',\n",
       " 'Verder',\n",
       " 'Verleidelijk',\n",
       " 'Verliefd',\n",
       " 'Verschrikkelijk',\n",
       " 'Verse',\n",
       " 'Verstandige',\n",
       " 'Vervolgens',\n",
       " 'Video',\n",
       " 'Vier',\n",
       " 'Vierdaagse',\n",
       " 'Vierentwintig',\n",
       " 'Vijf',\n",
       " 'Vink',\n",
       " 'Virtuele',\n",
       " 'Visueel',\n",
       " 'Visuele',\n",
       " 'Vlaamse',\n",
       " 'Vlieger',\n",
       " 'Vodafone',\n",
       " 'Voor',\n",
       " 'Vooral',\n",
       " 'Voorlopig',\n",
       " 'Voorlopige',\n",
       " 'Voortaan',\n",
       " 'Vorig',\n",
       " 'Vorige',\n",
       " 'Vreemd',\n",
       " 'Vreselijk',\n",
       " 'Vrij',\n",
       " 'Vrijwillig',\n",
       " 'Vroeger',\n",
       " 'Vroegtijdige',\n",
       " 'W',\n",
       " 'WAAROM',\n",
       " 'WAUW',\n",
       " 'WINE',\n",
       " 'Waanzinnig',\n",
       " 'Waar',\n",
       " 'Waarom',\n",
       " 'Waaronder',\n",
       " 'Waarschijnlijk',\n",
       " 'Wacht',\n",
       " 'Wakker',\n",
       " 'Wanneer',\n",
       " 'Want',\n",
       " 'Wars',\n",
       " 'Wauw',\n",
       " 'WeConnect',\n",
       " 'Webcare',\n",
       " 'Wederom',\n",
       " 'Weer',\n",
       " 'Weergaloos',\n",
       " 'Weg',\n",
       " 'Weird',\n",
       " 'Wekker',\n",
       " 'Wel',\n",
       " 'Weliswaar',\n",
       " 'Wellicht',\n",
       " 'Wellicious',\n",
       " 'Wenger',\n",
       " 'Were',\n",
       " 'Wereldmoe',\n",
       " 'Wereldwijd',\n",
       " 'Wereldwijde',\n",
       " 'Werkelijk',\n",
       " 'Werkze',\n",
       " 'West',\n",
       " 'WhatsApp',\n",
       " 'Wietse',\n",
       " 'Wijze',\n",
       " 'Wine',\n",
       " 'Wisselvallig',\n",
       " 'Witmer',\n",
       " 'Wordt',\n",
       " 'X',\n",
       " 'Xx',\n",
       " 'Yeah',\n",
       " 'Year',\n",
       " 'Yoga',\n",
       " 'Z',\n",
       " 'ZEGT',\n",
       " 'ZO',\n",
       " 'Zaanse',\n",
       " 'Zakelijk',\n",
       " 'Zakelijke',\n",
       " 'Zanzibar',\n",
       " 'Zee',\n",
       " 'Zeer',\n",
       " 'Zeker',\n",
       " 'Zelfs',\n",
       " 'Zes',\n",
       " 'Zet',\n",
       " 'Zeven',\n",
       " 'Zin',\n",
       " 'Zivkovic',\n",
       " 'Zo',\n",
       " 'Zodoende',\n",
       " 'Zoek',\n",
       " 'Zoet',\n",
       " 'Zojuist',\n",
       " 'Zomaar',\n",
       " 'Zonnig',\n",
       " 'Zuid',\n",
       " 'aah',\n",
       " 'aan',\n",
       " 'aangenaam',\n",
       " 'aangeraden',\n",
       " 'aanjager',\n",
       " 'aanrader',\n",
       " 'aanspreekbaar',\n",
       " 'aanstaande',\n",
       " 'aantrekkelijk',\n",
       " 'aantrekkelijker',\n",
       " 'aanvragen',\n",
       " 'aanwezig',\n",
       " 'aardig',\n",
       " 'aardige',\n",
       " 'abonnement',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absoluut',\n",
       " 'acceptabele',\n",
       " 'accounts',\n",
       " 'acht',\n",
       " 'achter',\n",
       " 'achteraf',\n",
       " 'achterlijk',\n",
       " 'achtertuin',\n",
       " 'achteruit',\n",
       " 'achtig',\n",
       " 'achtige',\n",
       " 'achttien',\n",
       " 'acquire',\n",
       " 'actie',\n",
       " 'actief',\n",
       " 'actiegerichte',\n",
       " 'actieve',\n",
       " 'activeer',\n",
       " 'actually',\n",
       " 'actueel',\n",
       " 'adorable',\n",
       " 'ads',\n",
       " 'af',\n",
       " 'afsluitdijk',\n",
       " 'aftermovie',\n",
       " 'afternoon',\n",
       " 'afwezig',\n",
       " 'ai',\n",
       " 'air',\n",
       " 'ajax',\n",
       " 'al',\n",
       " 'aldus',\n",
       " 'algehele',\n",
       " 'algemeen',\n",
       " 'algemene',\n",
       " 'allang',\n",
       " 'allebei',\n",
       " 'alleen',\n",
       " 'allemaal',\n",
       " 'aller',\n",
       " 'allerbeste',\n",
       " 'allereerste',\n",
       " 'allerliefste',\n",
       " 'aloud',\n",
       " 'already',\n",
       " 'alsnog',\n",
       " 'alternatief',\n",
       " 'alternatieve',\n",
       " 'altijd',\n",
       " 'alvast',\n",
       " 'alweer',\n",
       " 'ambitieuze',\n",
       " 'amused',\n",
       " 'an',\n",
       " 'analoge',\n",
       " 'analyse',\n",
       " 'and',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderhalf',\n",
       " 'anderhalve',\n",
       " 'andermans',\n",
       " 'anders',\n",
       " 'animal',\n",
       " 'animo',\n",
       " 'anonieme',\n",
       " 'another',\n",
       " 'ao',\n",
       " 'aparatische',\n",
       " 'apart',\n",
       " 'apathische',\n",
       " 'apetrots',\n",
       " 'app',\n",
       " 'appartement',\n",
       " 'april',\n",
       " 'are',\n",
       " 'asap',\n",
       " 'at',\n",
       " 'atletiek',\n",
       " 'atletisch',\n",
       " 'aug',\n",
       " 'authentiek',\n",
       " 'autobranche',\n",
       " 'automatisch',\n",
       " 'automatische',\n",
       " 'averechts',\n",
       " 'avondvierdaagse',\n",
       " 'award',\n",
       " 'awesome',\n",
       " 'az',\n",
       " 'baal',\n",
       " 'backed',\n",
       " 'badschuim',\n",
       " 'bang',\n",
       " 'based',\n",
       " 'bbele',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bedrijfspagina',\n",
       " 'beer',\n",
       " 'begrijpelijk',\n",
       " 'behoorlijk',\n",
       " 'beide',\n",
       " 'beiden',\n",
       " 'bejaarden',\n",
       " 'bekend',\n",
       " 'bekende',\n",
       " 'bekijk',\n",
       " 'belachelijk',\n",
       " 'belachelijke',\n",
       " 'belang',\n",
       " 'belangrijk',\n",
       " 'belangrijke',\n",
       " 'belangrijker',\n",
       " 'belangrijkst',\n",
       " 'belangrijkste',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'benodigde',\n",
       " 'bepaald',\n",
       " 'bereikbaar',\n",
       " 'berichten',\n",
       " 'beschikbaar',\n",
       " 'beschikbare',\n",
       " 'beslist',\n",
       " 'besluiteloos',\n",
       " 'bespaart',\n",
       " 'best',\n",
       " 'beste',\n",
       " 'besteld',\n",
       " 'beter',\n",
       " 'betere',\n",
       " 'betrouwbaar',\n",
       " 'betrouwbare',\n",
       " 'bewust',\n",
       " 'bewuste',\n",
       " 'bezig',\n",
       " 'beziq',\n",
       " 'bh',\n",
       " 'bij',\n",
       " 'bijna',\n",
       " 'bijvoorbeeld',\n",
       " 'bijzonder',\n",
       " 'bijzondere',\n",
       " 'billboard',\n",
       " 'binnen',\n",
       " 'binnenkort',\n",
       " 'biologische',\n",
       " 'birthday',\n",
       " 'bizar',\n",
       " 'bizarre',\n",
       " 'blame',\n",
       " 'blanco',\n",
       " 'blauw',\n",
       " 'blauwe',\n",
       " 'blessuregevoelig',\n",
       " 'blij',\n",
       " 'blije',\n",
       " 'blijkbaar',\n",
       " 'blogs',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'blote',\n",
       " 'blubberige',\n",
       " 'blut',\n",
       " 'boemerang',\n",
       " 'bomvol',\n",
       " 'boos',\n",
       " 'bots',\n",
       " 'bouwvakker',\n",
       " 'boven',\n",
       " 'boze',\n",
       " 'branche',\n",
       " 'brave',\n",
       " 'break',\n",
       " 'brede',\n",
       " 'breed',\n",
       " 'brenge',\n",
       " 'brings',\n",
       " 'brookemayo',\n",
       " 'bruin',\n",
       " 'btje',\n",
       " 'buiten',\n",
       " 'buitenlands',\n",
       " 'buitenlandse',\n",
       " 'buitenspeler',\n",
       " 'by',\n",
       " 'camera',\n",
       " 'capabele',\n",
       " 'care',\n",
       " 'cast',\n",
       " 'cc',\n",
       " 'censuursoftware',\n",
       " 'centraal',\n",
       " 'cerny',\n",
       " 'change',\n",
       " 'chatbots',\n",
       " 'check',\n",
       " 'checken',\n",
       " 'chief',\n",
       " 'chipkaart',\n",
       " 'chique',\n",
       " 'choose',\n",
       " 'chronologische',\n",
       " 'cht',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "#numpy.set_printoptions(threshold=numpy.nan)\n",
    "x = []\n",
    "for i in range(0, len(df.Bericht)):\n",
    "    x.append(word_Count(df.Bericht[i]))\n",
    "                     \n",
    "#print x\n",
    "\n",
    "vec = DictVectorizer()\n",
    "\n",
    "words = vec.fit_transform(x).toarray()\n",
    "\n",
    "vec.get_feature_names()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Gebruiker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3621dfd33b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mtf_idf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mranking\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"berichten-09-06-2017_10-49.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtf_idf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-3621dfd33b16>\u001b[0m in \u001b[0;36mtf_idf\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtf_idf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0muser_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0musers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Users\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBericht\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gebruiker'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3621dfd33b16>\u001b[0m in \u001b[0;36mget_Users\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_Users\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0musers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGebruiker\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Gebruiker'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def get_Users(df):\n",
    "    users = []\n",
    "    for g in df.Gebruiker:\n",
    "        u = g.lower()\n",
    "        if u not in users:\n",
    "            users.append(u)    \n",
    "    return users\n",
    "\n",
    "def tf_idf(df):\n",
    "    messages = {}\n",
    "    total_word_counter_list = {}\n",
    "    word_counter_dict = {}\n",
    "    tf_idf = {}\n",
    "    user_counter = 0\n",
    "    users = get_Users(df)\n",
    "    for u in users:\n",
    "        messages.update({u:df.Bericht.loc[df['Gebruiker'] == u]})\n",
    "        user_counter = user_counter + 1\n",
    "    for u in users:\n",
    "        counter = 0\n",
    "        user_word_counter = 1\n",
    "        for sentence in messages[u]:\n",
    "            sentence = sentence.split()\n",
    "            for word in sentence:                \n",
    "                counter = counter + 1\n",
    "                if word not in word_counter_dict:\n",
    "                    word_counter_dict.update({word:{u:1}})\n",
    "                else:\n",
    "                    word_counter_dict.update({word:{u:user_word_counter + 1}})\n",
    "        total_word_counter_list.update({u:counter})\n",
    "    for u in users:\n",
    "        all_words_user = total_word_counter_list.get(u)\n",
    "        print(all_words_user)\n",
    "        for sentence in messages[u]:\n",
    "            sentence = sentence.split()\n",
    "            for word in sentence:\n",
    "                user_word = 0\n",
    "                word_user_1 = word_counter_dict.get(word)\n",
    "                word_user = word_user_1.get(u)\n",
    "                for u in users:\n",
    "                    user_word_1 = word_user_1.get(u)\n",
    "                    if user_word_1 is not None:\n",
    "                        user_word = user_word + user_word_1\n",
    "                ranking = (word_user/all_words_user)*(np.log(user_counter/user_word))\n",
    "                tf_idf.update({word:ranking})\n",
    "df = pd.read_csv(\"berichten-09-06-2017_10-49.csv\", sep=';')\n",
    "tf_idf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Schiphol Bedankt toppers! Ik ben veilig in Barcelona 😊 #MAYTHEFORCEBEWITHYOU \n",
      "Bedankt toppers Ik ben veilig in Barcelona\n",
      "Thanks toppers I am safe in Barcelona\n",
      "\n",
      "\n",
      "#SavageMKTG: een tof programma over o.a. advertising, engagement en data. @OBILytics is van de partij, jij ook? http://obilytics.com/obilytics-partner-van-savage-marketing/ https://t.co/JB6PgencUx \n",
      "een tof programma over o a advertising engagement en data is van de partij jij ook\n",
      "a great program about o a advertising engagement and data is of the party you\n",
      "\n",
      "\n",
      "@puur Vond ik ook! \n",
      "Vond ik ook\n",
      "I also\n",
      "\n",
      "\n",
      "Hoe je met een slippertje 60.000 LinkedIn views krijgt http://bit.ly/2sJKKLq \n",
      "Hoe je met een slippertje 60 000 LinkedIn views krijgt\n",
      "How to get a one-night stand with 60 000 LinkedIn views\n",
      "\n",
      "\n",
      "@puellae_art Sporten gaat inderdaad gewoon door. 🤙🏼 \n",
      "Sporten gaat inderdaad gewoon door\n",
      "Sports is just by\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from translate import Translator\n",
    "\n",
    "translator= Translator(from_lang=\"nl\", to_lang=\"en\")\n",
    "for i in range(0,5):\n",
    "    bericht= df.Bericht[i]\n",
    "    print(bericht)\n",
    "    b = re.sub('@'+'\\w+','',bericht)\n",
    "    b = re.sub('#'+'\\w+','',b)\n",
    "    b = re.sub('http'+'\\S+', '', b)\n",
    "    b = re.findall('\\w+', b)\n",
    "    b = ' '.join(b)\n",
    "    print b\n",
    "    print(translator.translate(b))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0833333333333\n",
      "0.333333333333\n",
      "0.0714285714286\n"
     ]
    }
   ],
   "source": [
    "word = wn.synset('football.n.01')\n",
    "\n",
    "label1 = wn.synset('politics.n.01')\n",
    "label2 = wn.synset('sport.n.01')\n",
    "label3 = wn.synset('food.n.01')\n",
    "\n",
    "print word.path_similarity(label1) \n",
    "print word.path_similarity(label2)\n",
    "print word.path_similarity(label3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
